{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd47e68-6f94-41b0-9a5d-2e31aa6966d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Regex:\n",
    "\n",
    "# for distinct 5 letter words w eaAE as second letter\n",
    "\n",
    "regex = sorted(re.findall(r'\\b(\\w[aAeE]\\w{3})\\b',alice))\n",
    "for word in sorted(set(regex)):\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2262baf-5f23-49a7-961a-f05f31455a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulations\n",
    "#1) will u match ten of 20 cities right? what is prob you earn at least 2 points\n",
    "\n",
    "countries = [1,2,3,4,5,6,7,8,9,10]\n",
    "city_names=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "\n",
    "at_least_2 = 0\n",
    "for i in range(10000):\n",
    "    correct = 0\n",
    "    random.shuffle(countries)\n",
    "    random.shuffle(city_names)\n",
    "    for i in range(10):\n",
    "        country = countries[i]\n",
    "        city = city_names[i]\n",
    "        if country == city:\n",
    "            correct += 1\n",
    "            \n",
    "    if correct >= 2:\n",
    "        at_least_2 +=1\n",
    "    \n",
    "probability = at_least_2/10000\n",
    "probability *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690fc603-7eb1-45d1-a98a-14f07689a93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "\n",
    "#lol, pull out lowest scores, avg\n",
    "\n",
    "# def grading(l):\n",
    "\n",
    "def grading(l):\n",
    "    lol=[]\n",
    "    for line in l:\n",
    "        scores = [int(ele) for ele in line[1]]\n",
    "        if len(scores) == 5:\n",
    "            sorted_s= sorted(scores)\n",
    "            scores = sorted_s[1:]\n",
    "        else:\n",
    "            sorted_s= sorted(scores)\n",
    "            scores = sorted_s[2:]\n",
    "        scores = scores\n",
    "        avg = np.mean(scores)\n",
    "        lol.append([line[0], avg])\n",
    "        \n",
    "    return lol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea1c4a0-9ee5-4e6a-be96-adfc77acf523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing arrrays\n",
    "\n",
    "# load in\n",
    "q4_name = np.load(\"q4a_name.npy\")\n",
    "q4_data = np.load(\"q4a_data.npy\")\n",
    "# ['fund_code' 'fund_type' 'years' 'alpha' 'Sharpe_d'] (115, 5)\n",
    "#print correlation between number of years and data available fro each fund and funds CAPM alpha\n",
    "#when answering this question, make sure to exclude any missing returns\n",
    "\n",
    "q4_filter = ~np.isnan(q4_data[:,3])\n",
    "q4_data2 = q4_data[q4_filter]\n",
    "\n",
    "yr = q4_data2[:, q4_name == 'years'].T\n",
    "alpha = q4_data2[:, q4_name == 'alpha'].T\n",
    "\n",
    "corr = np.corrcoef(yr, alpha)\n",
    "corr\n",
    "\n",
    "#OR\n",
    "\n",
    "# Filter out np.nan returns\n",
    "q4_filter = ~np.isnan(q4_data[:,3])\n",
    "q4_data2 = q4_data[q4_filter]\n",
    "q4_data.shape, q4_data2.shape\n",
    "# Calculate correlation coefficient\n",
    "corr = np.corrcoef(q4_data2[:,(q4_name=='years')+(q4_name=='alpha')].T)[0,1]\n",
    "print(f\"The correlation between alpha and years of data is {corr:6.4f}\")\n",
    "\n",
    "# Calculate and print the average number of years separately for each of the five fund_types. You should not exclude funds with missing returns when performing this calculation.\n",
    "\n",
    "q4_type = q4_data[:,1]\n",
    "\n",
    "for num in sorted(set(q4_type)):\n",
    "    num_y = np.mean(q4_data[:,2][q4_type==num])\n",
    "    print(f\"For type {num:1.0f}, the average number of years of data is {num_y:4.2f}.\")\n",
    "    \n",
    "#Calculate and print the average alpha when Sharpe_d = 1 and again when Sharpe_d = 0. Please limit this calculation to the subset of funds for which years = 20. If there are any funds with mising returns, you should exclude them from the calcuation.\n",
    "q4_year     = q4_data[:,2]\n",
    "q4_sharpe_d = q4_data[:,4] \n",
    "\n",
    "r_s1 = np.mean(q4_data[(q4_year==20)*(q4_sharpe_d==1)][:,3])\n",
    "r_s0 = np.mean(q4_data[(q4_year==20)*(q4_sharpe_d==0)][:,3])\n",
    "print(f\"Average alpha is {r_s1:7.4f} when Sharpe_d==1.\")\n",
    "print(f\"Average alpha is {r_s0:7.4f} when Sharpe_d==0.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7bd2dbf-e541-49e7-9ffa-3799ad9e56a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Simulating correlated returns\n",
    "# Large-cap stock index has mean 10.1%, std of 20.2%\n",
    "# Small-cap stock index has mean 12.5%, std of 32.3%\n",
    "\n",
    "# Goal: Simulate correlated returns for lc and sc stocks\n",
    "#       1. Assume the correlation coefficient is 0.00 -> cov = 0\n",
    "#       2. Assume the correlation coefficient is 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca25341-909e-44bd-abc6-c44de9f02edf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mean   = [0.101, 0.125]   # mean returns\n",
    "var_lc = 0.202**2\n",
    "var_sc = 0.323**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbbc32b-bba4-402f-8c50-6510f1c407fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cov    = [[var_lc, 0], [0, var_sc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7441c69d-e7be-4967-ab49-6857830864c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.multivariate_normal(mean,cov, 10000).shape  \n",
    "# -> 10000 rows and 2 columns\n",
    "\n",
    "np.random.multivariate_normal(mean,cov, 10000).T.shape\n",
    "# -> 2 rows and 10000 columns\n",
    "\n",
    "x1, y1 = np.random.multivariate_normal(mean,cov, 10000).T\n",
    "x1.shape, y1.shape\n",
    "\n",
    "np.corrcoef(x1,y1)\n",
    "\n",
    "# x1, y1 are 10000 pairs of uncorrelated stock returns\n",
    "# Calculate the covariance when the correlation coefficient is 0.75\n",
    "cov_ls = (0.75)*(0.202)*(0.323)\n",
    "cov    = [[var_lc, cov_ls], [cov_ls, var_sc]]\n",
    "x2, y2 = np.random.multivariate_normal(mean,cov, 10000).T\n",
    "np.corrcoef(x2,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cde037-01fe-4238-96de-38d76813c3d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Regressions\n",
    "#R squared means we are explaing __% of data by this regression\n",
    "# We'll use this function most of the time\n",
    "\n",
    "def reg_m(y,x):\n",
    "    X = sm.add_constant(x)          # adds a column of 1s if necessary\n",
    "    results = sm.OLS(y, X).fit()  # results is the object containing regression estimates\n",
    "    return results\n",
    "\n",
    "reg_out = reg_m(y,x)\n",
    "print(reg_out.summary(xname=['constant','x']))\n",
    "reg_out.pvalues\n",
    "reg_out.params  # estimated parameters\n",
    "reg_out.tvalues[0], reg_out.tvalues[1]\n",
    "\n",
    "# Multivariate regressions\n",
    "# 1: simulate data\n",
    "np.random.seed(100)\n",
    "\n",
    "x2 = np.random.normal(0,2,(1000,1))\n",
    "w2 = np.random.normal(0,2,(1000,1))\n",
    "e2 = np.random.normal(0,10,(1000,1))\n",
    "#2 horizontally stack\n",
    "X2 = np.hstack((x2,w2))\n",
    "reg_m(y2,X2).summary(xname=['constant','x2','w2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b6e5c-7384-48c8-8b70-75e8d6d2f381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimating factor models with monthly returns\n",
    "# Goal: Extract the array of years\n",
    "yr     = m[:, m_names=='year'].reshape(36,)   # year filter\n",
    "rf     = m[:, m_names=='rf'].reshape(36,1)    # column of risk-free returns\n",
    "y      = m[:, m_names=='mret'].reshape(36,1)  # column of AAPL monthly returns\n",
    "mktrf  = m[:, m_names=='mktrf'].reshape(36,1) # column of CAPM market factor returns\n",
    "y_rf   = y - rf    # removes the risk-free rate from AAPL's monthly returns\n",
    "reg_m(y_rf,mktrf).summary(xname=['CAPM alpha','CAPM beta'])\n",
    "\n",
    "#This gives your CAPM alpha of 0.0039, what does this mean?\n",
    "# beta of 1.2 tells your AAPL is riskier than a typical firm in the mkt\n",
    "# Due to confidence interval, alpha might not be positive so it doesn't say much\n",
    "# yes beta is above 1 but may not be\n",
    "\n",
    "# if did this again with a year filter for two years:\n",
    "year_filter = (yr==2016) | (yr==2017)   # | means or  and    + means or\n",
    "reg_m(y_rf[year_filter],mktrf[year_filter]).summary(xname=['CAPM alpha','CAPM beta'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2605b094-a2aa-4b95-a6d1-b102b865d1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Estimate 3-factor alpha and betas\n",
    "smb = m[:,m_names=='smb'].reshape(36,1)\n",
    "hml = m[:,m_names=='hml'].reshape(36,1)\n",
    "X   = np.hstack((mktrf,smb,hml))\n",
    "\n",
    "reg_m(y_rf,X).summary(xname=['FF alpha','FF beta','SMB','HML'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4797714-0757-4da0-888c-5b68f51e1b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: Estimate a separate CAPM alpha for each calendar year\n",
    "\n",
    "for year in sorted(set(yr)):\n",
    "    reg_out = reg_m(y_rf[yr==year],mktrf[yr==year])\n",
    "    print(f'{year} -- {reg_out.params[0]:7.4f} -- {reg_out.pvalues[0]:7.4f}')\n",
    "\n",
    "# 0 is alpha, p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed55c0ae-0de0-44bb-acd0-80a09ee46b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How would we test whether Apple's CAPM alpha in Q4 is statistically significantly\n",
    "# different than its alpha in Q1-Q3?\n",
    "\n",
    "# Standard pooled regression\n",
    "# Q1 -> [y] = [1 x]\n",
    "# Q2 -> [y] = [1 x]\n",
    "# Q3 -> [y] = [1 x]\n",
    "# Q4 -> [y] = [1 x]\n",
    "\n",
    "# Allow return in Q4 to differ from other returns\n",
    "# Q1 -> [y] = [1 0 x]\n",
    "# Q2 -> [y] = [1 0 x]\n",
    "# Q3 -> [y] = [1 0 x]\n",
    "# Q4 -> [y] = [1 1 x]\n",
    "\n",
    "mm = [str(element)[4:6] for element in m[:,0]]\n",
    "q4 = [1 if element in ['10','11','12'] else 0 for element in mm]   # list comp version of np.where\n",
    "q4 = np.array(q4).reshape(36,1)\n",
    "X = np.hstack((q4,mktrf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15aec61-b903-42a8-9a99-2adbfbf270da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Omitted Variable Bias -- have a statistical model and missing a variable you care about\n",
    "# this missing variable is correlated to the variables you include\n",
    "\n",
    "np.random.seed(100)\n",
    "\n",
    "#random variables\n",
    "x3 = np.random.normal(0,2,(1000,1))\n",
    "#make them correlated\n",
    "w3 = x3 + np.random.normal(0,2,(1000,1))\n",
    "e3 = np.random.normal(0,10,(1000,1))\n",
    "\n",
    "\n",
    "y3 = 2 + 2*x3 + 3*w3 + e3\n",
    "X3 = np.hstack((x3,w3))\n",
    "reg_m(y3,X3).summary(xname=['constant','x3','w3']) #this includes all three and gets right variables\n",
    "\n",
    "# BUT what if you do # Omitted variable bias when excluding w3\n",
    "reg_m(y3,x3).summary(xname=['constant','x3'])\n",
    "# causes overestimate\n",
    "\n",
    "#If you are just being asked about return, don't need to subtract rf, when doing a Factor return always need to subtract the rf\n",
    "# trying to explain apples excess return vs markets excess return over rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b5f1e2-e4fb-41e3-b70f-45c0eb502fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Factor models with daily returns\n",
    "ff_names = np.load('ff_names.npy')\n",
    "ff_dates = np.load('ff_dates.npy')\n",
    "ff_rets  = np.load('ff_rets.npy')\n",
    "\n",
    "ff_mktrf = ff_rets[:,ff_names=='mktrf']\n",
    "ff_smb   = ff_rets[:,ff_names=='smb']\n",
    "ff_hml   = ff_rets[:,ff_names=='hml']\n",
    "ff_rf    = ff_rets[:,ff_names=='rf']\n",
    "\n",
    "FF = np.hstack((ff_mktrf,ff_smb,ff_hml))\n",
    "\n",
    "aapl_drets = np.load('aapl_dret.npy')\n",
    "aapl_dates = np.load('aapl_dates.npy')\n",
    "tsla_drets = np.load('tsla_dret.npy')\n",
    "tsla_dates = np.load('tsla_dates.npy')\n",
    "\n",
    "np.corrcoef(aapl_drets.T,tsla_drets.T)\n",
    "\n",
    "\n",
    "# Goal: Calculate correlation matrix for AAPL, TSLA, and MKTRF\n",
    "X = np.hstack((aapl_drets,tsla_drets,ff_mktrf))\n",
    "np.corrcoef(X.T)\n",
    "# Estimate some factor models\n",
    "tsla_rf = tsla_drets - ff_rf\n",
    "aapl_rf = aapl_drets - ff_rf\n",
    "\n",
    "# Estimate CAPM alpha and beta for AAPL using all dates\n",
    "reg_m(aapl_rf,ff_mktrf).summary(xname=['CAPM alpha','CAPM beta'])\n",
    "\n",
    "# Tsla's CAPM alpha and beta\n",
    "reg_m(tsla_rf,ff_mktrf).summary(xname=['CAPM alpha','CAPM beta'])\n",
    "# Goal: Estimate F-F 3-factor model for TSLA\n",
    "reg_m(tsla_rf,FF).summary(xname=['FF3 alpha','FF3 beta','SMB','HML'])\n",
    "\n",
    "\n",
    "\n",
    "#For pooled regression, stack returns for tsla and aapl and stack FF returns\n",
    "# ASIDE ON REGRESSION SPECIFICATIONS\n",
    "\n",
    "# Single regressions:   \n",
    "# [y_aapl] = [1 FF]\n",
    "\n",
    "# Pooled regression:\n",
    "# [y_aapl] = [1 FF]\n",
    "# [y_tsla] = [1 FF]\n",
    "\n",
    "y_pooled = np.vstack((aapl_rf,tsla_rf))\n",
    "FF_pooled = np.vstack((FF,FF))\n",
    "# Pooled 3-Factor model for AAPL and TSLA ; this is assuming that aapl and tsla have same alpha and factor loading\n",
    "reg_m(y_pooled,FF_pooled).summary(xname=['FF3 alpha','FF3 beta','SMB','HML'])\n",
    "\n",
    "# How would we estimate a separate CAPM alpha for AAPL each calendar year?\n",
    "year = np.array([element[0:4] for element in aapl_dates])\n",
    "year = year.reshape(-1)   # this removes the structure\n",
    "for y in sorted(set(year)):\n",
    "    reg_out = reg_m(aapl_rf[year==y],ff_mktrf[year==y])\n",
    "    print(f'{y}   {reg_out.params[0]:7.4f}    ({reg_out.pvalues[0]:7.4f})')\n",
    "    \n",
    "# How does Apple's CAPM beta vary over the 8 calendar years?\n",
    "for y in sorted(set(year)):\n",
    "    reg_out = reg_m(aapl_rf[year==y],ff_mktrf[year==y])\n",
    "    print(f'{y}   {reg_out.params[1]:7.4f}    ({reg_out.pvalues[1]:7.4f})')\n",
    "    \n",
    "# Does AAPL's CAPM beta differ from TSLA's CAPM beta?\n",
    "# # Testing for differences...\n",
    "\n",
    "# POOLED\n",
    "# [y_aapl] = [1 mktrf]\n",
    "# [y_tsla] = [1 mktrf]\n",
    "\n",
    "# ALLOWING FOR DIFFERENCES\n",
    "# [y_aapl] = [1 0 mktrf     0]\n",
    "# [y_tsla] = [1 1 mktrf mktrf]\n",
    "\n",
    "aapl_stack = np.hstack((np.zeros(ff_mktrf.shape),ff_mktrf,np.zeros(ff_mktrf.shape)))\n",
    "tsla_stack = np.hstack((np.ones(ff_mktrf.shape), ff_mktrf,ff_mktrf))\n",
    "FF_stack = np.vstack((aapl_stack,tsla_stack))\n",
    "\n",
    "reg_m(y_pooled,FF_stack).summary(xname=['AAPL CAPM alpha','TSLA-AAPL CAPM alpha',\n",
    "                                        'AAPL CAPM beta', 'TSLA-AAPL CAPM beta'])\n",
    "\n",
    "# Estimate separate Q1, Q2, Q3, Q4 alphas in a pooled regression with a single CAPM beta\n",
    "qq = np.array([element[4:6] for element in ff_dates])\n",
    "q1 = np.where((qq=='01')+(qq=='02')+(qq=='03'),1,0).reshape(ff_mktrf.shape)\n",
    "q2 = np.where((qq=='04')+(qq=='05')+(qq=='06'),1,0).reshape(ff_mktrf.shape)\n",
    "q3 = np.where((qq=='07')+(qq=='08')+(qq=='09'),1,0).reshape(ff_mktrf.shape)\n",
    "q4 = np.where((qq=='10')+(qq=='11')+(qq=='12'),1,0).reshape(ff_mktrf.shape)\n",
    "QQ = np.hstack((q1,q2,q3,q4,ff_mktrf))\n",
    "reg_m(aapl_rf,QQ).summary()\n",
    "sm.OLS(aapl_rf,QQ).fit().summary(xname=['Q1','Q2','Q3','Q4','beta'])\n",
    "\n",
    "# How would we test whether AAPL's alpha and/or beta are different after 20191231?\n",
    "\n",
    "# [aapl_rf] = [1 0 mktrf 0]     <= dates through 20191231\n",
    "# [aapl_rf] = [1 1 mktrf mktrf] <= dates after 20191231\n",
    "\n",
    "y2020 = np.where(years>='2020',1,0)\n",
    "mktrf2020 = ff_mktrf*y2020\n",
    "y2020 = np.where(years>='2020',1,0).reshape(ff_mktrf.shape)\n",
    "mktrf2020 = ff_mktrf*y2020\n",
    "\n",
    "YY = np.hstack((y2020,ff_mktrf,mktrf2020))\n",
    "reg_m(aapl_rf,YY).summary(xname=['AAPL alpha before 2020','AAPL alpha after - before',\n",
    "                                'AAPL beta before 2020','AAPL beta after - before'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747ec237-4eb7-47e9-a40a-e69979bf5861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Is Apple's alpha statistically significantly higher or lower in Q4 than in the other quarters?\n",
    "mm = [str(element)[4:6] for element in m[:,0]]\n",
    "set(mm)\n",
    "q4 = [1 if element in ['10','11','12'] else 0 for element in mm]\n",
    "q4 = np.array(q4).reshape(36,1)\n",
    "print(q4[0:12], np.mean(q4))\n",
    "X2 = np.hstack((q4, mktrf, smb, hml))\n",
    "print(reg_m(y, X2).summary(xname=['alpha','q4','mktrf','smb','hml']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd86280-2c1d-4451-ad1e-fbbbe6095467",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.array(['A']*100 + ['B']*100 + ['C']*100).reshape(300,1)\n",
    "\n",
    "# Create 100 observations each for A, B, and C and stack them into a single column\n",
    "\n",
    "a = np.random.normal(0.5,0.01,(100,1))\n",
    "b = np.random.normal(1.0,0.01,(100,1))\n",
    "c = np.random.normal(3.0,0.01,(100,1))\n",
    "\n",
    "y = np.vstack((a,b,c))\n",
    "y.shape\n",
    "# Set of potential independent variables\n",
    "\n",
    "x0 = np.ones((300,1))          # equals one for all 300 obs\n",
    "x1 = np.where(names=='A',1,0)  # equals one for Stock A, zero otherwise\n",
    "x2 = np.where(names=='B',1,0)  # equals one for Stock B, zero otherwise\n",
    "x3 = np.where(names=='C',1,0)  # equals one for Stock C, zero otherwise\n",
    "\n",
    "# For each stock, we regress y on the subset of x0 that corresponds to the stock\n",
    "# Notice that we are using the stock name as a row filter\n",
    "\n",
    "for stock in ['A','B','C']:\n",
    "    # regression keeps subset of observations for single stock\n",
    "    reg_out = sm.OLS(y[names==stock], x0[names==stock]).fit()\n",
    "    print(f'Stock {stock}   {reg_out.params[0]:7.4f} with std error of {reg_out.bse[0]:7.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d8f980-0652-459f-8205-06c70e765262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want to limit the data to be between 20161001 and 20230731?\n",
    "\n",
    "keep = (date>='20161001') * (date<='20230731')\n",
    "date = date[keep]\n",
    "r    = r[keep]\n",
    "\n",
    "# This function incorporates the various steps above\n",
    "# returns unstructured date filter and structured array of daily returns\n",
    "\n",
    "def returns(ticker):\n",
    "    # data is a pandas DataFrame, which is related to an array\n",
    "    data = yf.download(ticker, start=\"2016-9-30\", end=\"2023-10-31\", progress=False)[[\"Adj Close\"]]\n",
    "    # adj is the array corresponding to the column of data of adjusted closing prices\n",
    "    adj  = np.array(data[['Adj Close']])\n",
    "    # calculates daily returns from adjusted closing prices\n",
    "    r     = np.ones(adj.shape)\n",
    "    r[0]  = np.nan\n",
    "    r[1:] = adj[1:] / adj[0:-1] - 1\n",
    "    # date is extracted from the index of the data DataFrame\n",
    "    # data is formatted as '2016-09-26', but I slice around the dashes\n",
    "    date = list(data.index.astype(str))\n",
    "    date = [element[0:4]+element[5:7]+element[8:] for element in date]\n",
    "    date = np.array(date).reshape(r.size)\n",
    "    # create date filters and apply to both the date and return arrays\n",
    "    keep = (date>='20161001') * (date<='20230731')\n",
    "    date = date[keep]\n",
    "    r    = r[keep]\n",
    "    return (r, date)\n",
    "\n",
    "ticker_list = ['AIZ','MTB','BDX','OKE','MET','HII','OMC','WY','SPY']\n",
    "ret, dates = returns('AIZ')\n",
    "# create a new array and use it to stack each of the columns of returns\n",
    "# new columns are placed to the right of existing columns\n",
    "\n",
    "rets = ret.copy()\n",
    "for ticker in ticker_list[1:]:\n",
    "    ret, ret_date = returns(ticker)   # Downloads data\n",
    "    rets = np.hstack((rets,ret))      # Adds to rets array\n",
    "    \n",
    "    # ticker_list can be used as a row filter\n",
    "\n",
    "ticker_list = np.array(ticker_list)\n",
    "ticker_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a81ffb6-3932-4e47-9654-d72b454a9adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate when allocation to SC is 50%, rho = 0, AUM = $1 million, cutoff = $1 million\n",
    "\n",
    "print(\"Probability of a negative return when investing 50% in SC: {:5.2f}%\".\n",
    "      format(100*pr_loss(50, 0, 1000000, 1000000)))\n",
    "\n",
    "def pr_loss(alloc_sc, rho, aum, cutoff):\n",
    "    \n",
    "    # dollar allocation to bond and small cap for given 'alloc_sc'\n",
    "    alloc   = np.array([aum * (1-(alloc_sc/100)), aum * (alloc_sc/100)])  \n",
    "\n",
    "    # covariance that gives desired correlation coef.\n",
    "    c       = rho*0.031*0.323                                          \n",
    "    mean    = [1.035, 1.125]                     # average **gross** returns of bonds and small cap\n",
    "    cov     = [[0.031**2, c], [c, 0.323**2]]     # incorporates desired correlation in returns\n",
    "\n",
    "    # draws 100000 pairs of bond and stock returns\n",
    "    # array is (100000,2) because we simulate single\n",
    "    # stock and single bond return in each iteration\n",
    "    # replaces negative gross returns with zero\n",
    "    \n",
    "    returns = np.random.multivariate_normal(mean, cov, 100000)  \n",
    "    returns[returns<0] = 0\n",
    "    \n",
    "    # convert returns to FVs and then sums each row\n",
    "    # each element in column 0 multipled by $ allocation to bonds\n",
    "    # each element in column 1 multipled by $ allocation to stocks\n",
    "    # FVs for stocks and bonds are summed within each row\n",
    "    value   = np.sum(returns*alloc, axis=1)\n",
    "    \n",
    "    return  np.mean(value<cutoff)       # returns fraction of rows with FV below cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd890c25-2df8-4553-9329-8f561bc387a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "winner = []\n",
    "\n",
    "for r in np.arange(-1,1.01,0.1):\n",
    "    # holding correlation coefficient constant, calculate probability\n",
    "    # of negative return for allocations to SC of 0%, 1%, ..., 99%, 100%\n",
    "    sim_loss  = [(a, pr_loss(a, r, 1000000,1000000)) for a in range(0,101,1)]  \n",
    "    # extracts highest allocation to SC with probability of loss < 20%\n",
    "    win_alloc = [tup for tup in sim_loss if tup[1]<0.20][-1]\n",
    "    winner.append([r,win_alloc[0]])\n",
    "    # calculates expected return based on 'winning' allocation\n",
    "    e_ret = (1-win_alloc[0]/100)*3.5 + (win_alloc[0]/100)*12.5\n",
    "    \n",
    "    print(\"rho {:5.2f}, allocating {:5.2f}% to SC equity implies E[return] of {:4.2f}% and Pr(loss) of {:5.2f}%\"\n",
    "          .format(r,win_alloc[0], e_ret, win_alloc[1]*100))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a09312b-cd67-4a43-9be6-93b4d7b0859d",
   "metadata": {},
   "source": [
    "In-class exercises\n",
    "What is AAPL's average daily return during 2020Q1?\n",
    "What is the correlation in daily returns of SMB and HML?\n",
    "Create a date array containing calendar years\n",
    "What is the standard deviation of MKTRF during each calendar year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204bfa3-c064-45a1-a029-8bf383b05354",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(aapl_drets[(aapl_dates>='20200101') * (aapl_dates<='20200331')])\n",
    "\n",
    "np.corrcoef(ff_smb.T,ff_hml.T)\n",
    "\n",
    "# 3. Create date array containing calendar years\n",
    "years = np.array([element[0:4] for element in ff_dates])\n",
    "\n",
    "# 4. What is the standard deviation of MKTRF during each calendar year?\n",
    "np.std(ff_mktrf[years=='2020'])\n",
    "\n",
    "for y in sorted(set(years)):\n",
    "    print(y, np.std(ff_mktrf[years==y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb044c85-012c-4413-8184-366b3ec10b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of regression coefficients from a simulation\n",
    "alpha = []\n",
    "beta  = []\n",
    "for num in range(10000):\n",
    "    x = np.random.normal(0,1,(1000,1))\n",
    "    y = -1 + 2*x + np.random.normal(0,10,(1000,1))\n",
    "    reg_out = reg_m(y,x)\n",
    "    a, b = reg_out.params\n",
    "    alpha.append(a)\n",
    "    beta.append(b)\n",
    "\n",
    "plt.hist(alpha, np.linspace(-3,1,81), color='Rebeccapurple')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(d.keys(),d.values())\n",
    "plt.xlabel('Letter')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "plt.bar(d.keys(),d.values())\n",
    "plt.xlabel('Letter')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "# Loading daily returns\n",
    "returns = np.load('2.7_returns.npy')\n",
    "tickers = np.load('2.7_tickers.npy')\n",
    "dates   = np.load('2.7_dates.npy')\n",
    "\n",
    "plt.scatter(returns[tickers=='BDX'],returns[tickers=='SPY'])\n",
    "plt.title('Scatter of BDX versus SPY')\n",
    "plt.show()\n",
    "np.corrcoef(returns[tickers=='BDX'],returns[tickers=='SPY'])\n",
    "\n",
    "# We can run a 'CAPM-style' regression\n",
    "# (I am not adjusting for the level of the risk-free rate)\n",
    "\n",
    "y = returns[tickers=='BDX'].T\n",
    "x = returns[tickers=='SPY'].T\n",
    "\n",
    "reg_out = reg_m(y,x)\n",
    "\n",
    "plt.scatter(x,y,color='b')\n",
    "plt.plot(x, reg_out.params[0] + reg_out.params[1]*x, color='r')\n",
    "plt.show()\n",
    "\n",
    "print(f'Regression line is {reg_out.params[0]:.4f} + {reg_out.params[1]:.4f} * x')\n",
    "\n",
    "spy = returns[tickers=='SPY'].reshape(-1) # 'list' of daily returns\n",
    "met = returns[tickers=='MET'].reshape(-1) # 'list' of daily returns\n",
    "\n",
    "plt.plot(met)\n",
    "plt.plot(spy,alpha=0.5,c='r')\n",
    "plt.show()\n",
    "\n",
    "np.std(met), np.std(spy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420fe057-deab-4373-bca3-cda99605fc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Farma French 3-factor model for Stock A\n",
    "a_rf = stock_ret[:,stock_name=='A'] - ff_ret[:,ff_name=='rf']\n",
    "#[0:3] takes mktrf, smb, hml\n",
    "reg_m(a_rf,ff_ret[:,0:3]).summary(xname=['alpha','mktrf beta','smb beta','hml beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae22972-ad8e-4045-9a03-0674b326111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Constant: Daily return is +2 basis points above what is predicted by CAPM beta, but the difference is statistically insignificant (p-value of 0.703).\n",
    "Mktrf: Market beta is estimated to be around 0.53; because the 95 percent confidence interval is between 0.47 and 0.59, we are highly confident that the market risk is below average.\n",
    "SMB: Estimated coefficient is negative and statistically significant from zero, suggesting that the stock is a large cap stock.\n",
    "HML: Estimated coefficient is negative and statistically significant from zero, suggesting that the stock is a growth stock. That said, the estimated coefficient and the upper end of the 95th percent confidence interval are both close to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169fdc92-fd8b-402e-9ce1-6950c731e726",
   "metadata": {},
   "source": [
    "Use an OLS regression to test whether the average return for stocks B and C in 2020 is statistically significantly different than the average return for stocks A and D in 2020. Extract the relevant parameter and p-value from the output of reg_m() and use them to print a statement that explains whether the estimated difference is statistically significant from zero at the 5-percent level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c383f0-c4ea-4594-ac7d-211745bdcdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = stock_ret[(stock_date>=\"20200101\")*(stock_date<=\"20201231\"),:][:,stock_name=='A']\n",
    "b = stock_ret[(stock_date>=\"20200101\")*(stock_date<=\"20201231\"),:][:,stock_name=='B']\n",
    "c = stock_ret[(stock_date>=\"20200101\")*(stock_date<=\"20201231\"),:][:,stock_name=='C']\n",
    "d = stock_ret[(stock_date>=\"20200101\")*(stock_date<=\"20201231\"),:][:,stock_name=='D']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3623cb03-cfd4-466c-94b5-fc0c721f7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = np.vstack((a,b,c,d))\n",
    "x = np.vstack((np.ones((rows,1)),np.zeros((rows,1)),np.zeros((rows,1)),np.ones((rows,1))))\n",
    "# here u are putting ones in for A & D\n",
    "#[A] = [1 1]\n",
    "#[B] = [1 0]\n",
    "#[C] = [1 0]\n",
    "#[D] = [1 1]\n",
    "# The column of 1s measures the average return on B&C; this is the constant term. The 1/0 column measures the difference between the average return on stocks A&D and the average return on stocks B&C. We use the p-value on this coefficient to test whether the difference is statistically significant\n",
    "r.shape, x.shape, np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c356a-e33b-4444-9276-11033076a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_out = reg_m(r,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2b81a6-c4a0-4a37-a497-1b45ae4d7690",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_out.summary(xname=[\"(Ave B and C)\",\"(Ave A and D) - (Ave B and C)\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a4f54a-ea38-4f90-94ea-92c0d168ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reg_out.pvalues[1]<= 0.05:\n",
    "    print(f\"Yes, stocks A and D do have statistically significantly different returns. The coefficient\\n\\\n",
    "    on the difference of {reg_out.params[1]:7.4f} is statistically significant at the 5-percent level\\n\\\n",
    "    (p-value of {reg_out.pvalues[1]:6.4f}).\") \n",
    "else:\n",
    "    print(f\"No, stocks A and D do have statistically significantly different returns. The coefficient\\n\\\n",
    "    on the difference of {reg_out.params[1]:7.4f} is not statistically significant at the 5-percent level\\n\\\n",
    "    (p-value of {reg_out.pvalues[1]:6.4f}).\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a0eb41-d82e-4c41-ab42-66489a18ab8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See where sharpe ratio > 0\n",
    "\n",
    "\n",
    "returns = np.random.normal(0.1052, 0.1538, 1000000)\n",
    "SR = (returns - .01) / .1538\n",
    "neg_SR = np.where(SR<0,1,0)\n",
    "prob_neg = np.mean(neg_SR)\n",
    "print(\"The probability of a negative Sharpe Ratio is {:5.2f}%.\".format(100*prob_neg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f215f4d-4482-4f38-b6ba-ab6f411523f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate CAPM model for stock A \n",
    "a_rf = rets[:,ticker=='A'] - ff_ret[:,ff_name=='rf'].reshape(1258,1)\n",
    "ff_1 = ff_ret[:,ff_name=='mktrf'].reshape(1258,1)\n",
    "stockA = reg_m(a_rf, ff_1)\n",
    "stockA.summary(xname=['Alpha','Mktrf'])\n",
    "\n",
    "#Estimate 3-factor model for stock A\n",
    "ff_2 = ff_ret[:, ff_name!= 'rf'].reshape(1258,3)\n",
    "fff = reg_m(a_rf, ff_2)\n",
    "fff.summary(xname = ['Alpha','Mktrf','SMB','HML'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0bf140-64a4-473e-b816-6bde963a949d",
   "metadata": {},
   "source": [
    "- Alpha: An Alpha of ~.5% is positive and within the confidence interval. signifies that stock, it is highly statistically significant as p value is 0.\n",
    "- Mktrf: MKTRF beta of -.-311 is statistically indistinguishable from 0 as p value is 0.374.\n",
    "- SMB: SMB loading is well above one, with p-value of 0.000. This is a small stock.\n",
    "- HML:  HML loading is well above one, with p-value of 0.000. This is a value stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11240bc5-4788-4a37-94fd-bb278575c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the CAPM beta for stock B is statistically\n",
    "#signficantly different at 10% level in last two years (2020-21)\n",
    "\n",
    "b_rf = rets[:,ticker=='B'] - ff_ret[:,ff_name=='rf'].reshape(1258,1)\n",
    "mktrf = ff_ret[:,ff_name=='mktrf'].reshape(1258,1)\n",
    "b_rf.shape, mktrf.shape\n",
    "\n",
    "later   = np.where(date>='20200101',1,0).reshape(1258,1)\n",
    "l_mktrf = later*mktrf.reshape(1258,1)\n",
    "\n",
    "X = np.hstack((mktrf,later,l_mktrf))\n",
    "X.shape\n",
    "\n",
    "reg_out = reg_m(b_rf,X)\n",
    "reg_out.summary(xname=['Alpha','Mktrf','Alpha*(2020-2021)','Mktrf*(2020-2021)'])\n",
    "if reg_out.pvalues[3]<= 0.1:\n",
    "    print(f\"Yes, stock B's CAPM beta is statistically significantly different in the last two years. The\\n\\\n",
    "difference of {reg_out.params[3]:7.4f} is statistically significant (p-value of {reg_out.pvalues[3]:6.4f}).\") \n",
    "else:\n",
    "    print(f\"No, stock B's CAPM beta is not statistically significantly different in the last two years. The\\n\\\n",
    "difference of {reg_out.params[3]:7.4f} is not statistically significant (p-value of {reg_out.pvalues[3]:6.4f}).\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f2506e-80a5-4a4e-aa41-51c01dfe1da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 MEANS COLUMNS, 1 MEANS ROWS\n",
    "\n",
    "q4_data2 = q4_data[(q4_date>=201807)&(q4_date<=202006)]\n",
    "\n",
    "\n",
    "q4b = np.sum(~np.isnan(q4_data2),axis=0)\n",
    "for num in range(len(q4_name)):\n",
    "    print(\"Stock\", q4_name[num], \"has\", q4b[num], \"nonmissing returns.\")\n",
    "#Sum up all columns of non missing returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae618d9-d2c3-4f14-b0e2-7a165bcd8eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stock A cumulative net return that is using non missing returns\n",
    "\n",
    "q4_dataA = q4_data[q4_name=='StockA']\n",
    "q4_dataA = q4_dataA[~np.isnan(q4_dataA)]\n",
    "q4c = np.cumprod(1+q4_dataA)[-1] - 1\n",
    "print(f'StockA has a cumulative net return of {100*q4c:4.2f}%, based on {q4_dataA.size} non-missing returns.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c15748-d71e-488a-9937-16f38241d008",
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate the cumulative net returns for each of the four stocks using the twelve monthly returns in 2021. Store the four ending values in (4,) array q4c and then print q4c. Again, there is no need to format the outpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75c98db-d429-4132-b279-80ad86bb0b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.cumprod(1+sim1, axis = 1) #cumulative product within each row\n",
    "np.cumprod(1+sim1, axis=1)[:,-1] -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67373af-6a0b-4a18-9298-b6ff115b56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q4_data3 = q4_data[(q4_date>=202101)&(q4_date<=202112)]\n",
    "q4_data3.shape\n",
    "q4c = np.cumprod(1+q4_data3, axis=0) -1\n",
    "q4c = q4c[-1]\n",
    "print(q4c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403abb2c-93c9-4737-9ad5-1226a29235fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_out = reg_m(y, x)\n",
    "\n",
    "plt.plot(x, y, '*', label='original data')\n",
    "plt.plot(x, reg_out.params[0] + reg_out.params[1]*x, 'r', label='fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83771da3-3bcc-4db0-910d-9fd817e9faa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create an array that can be used to identify the returns belonging to separate years and quarters (e.g., 2216Q4, 2017Q1, ..., 2023Q3). Feel free to use list comprehension, functions, etc. Name the array yyyyqq. Print sorted(set(yyyyqq)).\n",
    "\n",
    "yyyyqq = np.array([f'{date[:4]}Q{((int(date[4:6]) - 1) // 3) + 1}' for date in dates])\n",
    "print(sorted(set(yyyyqq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f745e508-96a6-4907-a524-439975c7d608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estimate a separate CAPM alpha for NVDA using daily returns corresponding to each value of yyyyqq. Store the estimates in a list or array and use plt.scatter() to plot them; x should be dates, y should be alphas. Please use plt.title() to give your plot a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651efb4e-f7d6-48d0-a723-e054814c3d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nvda = rets[:,names=='NVDA']\n",
    "ff_mktrf = ff[:,ff_names=='mktrf']\n",
    "ff_rf = ff[:,ff_names=='rf']\n",
    "nvda_rf = nvda - ff_rf\n",
    "\n",
    "capm_alpha = []\n",
    "for i in sorted(set(yyyyqq)):\n",
    "    reg_out = reg_m(nvda_rf[yyyyqq==i], ff_mktrf[yyyyqq==i])\n",
    "    capm_alpha.append(reg_out.params[0])\n",
    "\n",
    "plt.scatter(sorted(set(yyyyqq)), capm_alpha)\n",
    "plt.xticks(rotation = 90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f1be5-6572-4536-b7f2-2a50e83a6210",
   "metadata": {},
   "source": [
    " Use the full sample of data to test whether NVDA's CAPM alpha and CAPM beta are statistically different than Apple's CAPM alpha and CAPM beta (at a 95% confidence level in a two-sided test, which are the default assumptions for the displayed confidence intervals). Add a sentence or two that interprets the results of your hypotheses tests.\n",
    "\n",
    "You are free to structure your test so that the four variables are:\n",
    "\n",
    "NVDA's CAPM alpha\n",
    "AAPL's CAPM alpha - NVDA's CAPM alpha\n",
    "NVDA's CAPM beta\n",
    "AAPL's CAPM beta - NVDA's CAPM beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828b9e58-0310-4503-8744-5652975c6216",
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl_rf = rets[:,names=='AAPL'] - ff[:,ff_names=='rf']\n",
    "\n",
    "stacked_y = np.vstack((nvda_rf,aapl_rf))\n",
    "\n",
    "stacked_nvda = np.hstack((np.zeros(ff_mktrf.shape),ff_mktrf,np.zeros(ff_mktrf.shape)))\n",
    "stacked_aapl = np.hstack((np.ones(ff_mktrf.shape),  ff_mktrf,ff_mktrf))\n",
    "stacked_X    = np.vstack((stacked_nvda,stacked_aapl))\n",
    "\n",
    "reg_m(stacked_y,stacked_X).summary(xname=['NVDA alpha','AAPL alpha - NVDA alpha',\n",
    "                                          'NVDA beta','AAPL beta - NVDA beta'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ae8d5-6871-4405-91cd-f088530875fa",
   "metadata": {},
   "source": [
    "Interpretation: Apple's daily CAPM alpha is 8 basis points lower than Nvidia's. However, this difference is not statistically significant at conventional levels. Under the null hypothesis of no difference, the p-value is 0.211. In contrast, Apple's CAPM beta is 0.56 points lower than Nividia's CAPM beta, and this differences is highly significant (p-value rounds down to 0.000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee01c278-813e-4bf3-b91e-427f3ecff00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regress Costco's daily return on its daily return in the previous trading date and interpret the coefficient on lagged daily returns.\n",
    "cost = rets[:,names=='COST']\n",
    "cost_today = cost[1:]\n",
    "cost_lag   = cost[0:-1]\n",
    "\n",
    "print(\"  Today   Lagged\")\n",
    "print(\"-------  -------\")\n",
    "for num in range(5):\n",
    "    print(f'{cost_today[num][0]:7.4f}  {cost_lag[num][0]:7.4f}')\n",
    "    \n",
    "reg_m(cost_today,cost_lag).summary(xname=['constant','lagged return'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc0a76f-1c12-4979-bf1f-5a67eaf2e209",
   "metadata": {},
   "source": [
    "Interpretation: The coefficient on lagged returns is negative and statistically significant at the five percent level (p-value of 0.027). This tells us that when Costco's daily return is positive today it is more likely to be negative tomorrow, and vice versa. However, the R-squared (which tells us the fraction of the variation in today's stock return that can be explained by the lagged stock return) is very low.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89dd64-4df4-42f0-b4f5-896462db7875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estimate the Fama-French three-factor (FF3) model for Costco, using all of the daily returns for 2017 through 2021. Plot the excess returns on Costco against the excess returns on the market. Plot the predicted values from the FF3 model on the same graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45982205-ea47-4465-b028-a554d9b54a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.array([element[0:4] for element in dates])\n",
    "\n",
    "year_filter = (years>='2017') * (years<='2021')\n",
    "cost_rf = cost - ff[:,ff_names=='rf']\n",
    "\n",
    "y = cost_rf[year_filter]\n",
    "x = ff[:,ff_names=='mktrf'][year_filter]\n",
    "X = ff[:,ff_names!='rf'][year_filter]\n",
    "\n",
    "ð‘ƒð‘Ÿð‘’ð‘‘ð‘–ð‘ð‘¡ð‘’ð‘‘ð‘¡=ð›¼+ð›½ð‘€ð¾ð‘‡ð‘…ð¹âˆ—ð‘€ð¾ð‘‡ð‘…ð¹ð‘¡+ð›½ð‘†ð‘€ðµâˆ—ð‘†ð‘€ðµð‘¡+ð‘ð‘’ð‘¡ð‘Žð»ð‘€ð¿âˆ—ð»ð‘€ð¿ð‘¡\n",
    "\n",
    "reg_out = reg_m(y,X)\n",
    "pred_y  = reg_out.params[0] + reg_out.params[1]*X[:,0] + reg_out.params[2]*X[:,1] + reg_out.params[3]*X[:,2]\n",
    "\n",
    "plt.scatter(x,y, alpha=0.5)\n",
    "plt.scatter(x,pred_y, c='r', alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee97e7c-1c92-46ba-9e0f-9dc67bd51dcb",
   "metadata": {},
   "source": [
    "Please use the actual daily returns for each stock during 2020 to determine the annual buy-and-hold <i>net</i> return on this portfolio during 2020. Along the way, you will find it useful to calculate the cumulative annual <i>gross</i> return for each stock during 2020 (stored as `crets_2020` with shape (3,)), and to create an array with the three portfolio weights above (stored as `opt_w` with shape (1,3))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c34331-e917-4df3-b332-caaeaeaa6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.array([element[0:4] for element in dates])\n",
    "rets_2020  = rets[years=='2020']\n",
    "crets_2020 = np.cumprod(1+rets_2020, axis=0)[-1]   # gross returns\n",
    "crets_2020, crets_2020.shape, names\n",
    "opt_w    = np.array([0.13,0.47,0.40]).reshape(1,3) # same order as returns above\n",
    "opt_w * crets_2020    # weights times gross returns\n",
    "opt_gret = np.sum(opt_w * crets_2020) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dafb82-3d5b-4346-b33d-00ac54ea92b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Constant: Daily return is +2 basis points above what is predicted by CAPM beta, but the difference is statistically insignificant (p-value of 0.703).\n",
    "Mktrf: Market beta is estimated to be around 0.53; because the 95 percent confidence interval is between 0.47 and 0.59, we are highly confident that the market risk is below average.\n",
    "SMB: Estimated coefficient is negative and statistically significant from zero, suggesting that the stock is a large cap stock.\n",
    "HML: Estimated coefficient is negative and statistically significant from zero, suggesting that the stock is a growth stock. That said, the estimated coefficient and the upper end of the 95th percent confidence interval are both close to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7470f9df-0468-44ed-a1ec-e1eec4db3422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(l):\n",
    "    out = []\n",
    "    for line in l:\n",
    "        letter, *ret = line.split(',') # the * collects remainnig elements in list\n",
    "        r = [float(element) for element in ret]\n",
    "        out.append([letter, sum(r)/len(r), len(r)])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daabda08-e279-43c0-a124-60347a5a46a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For arrays, do this to have stock name be columns\n",
    "# then take max of non missing down columns\n",
    "\n",
    "q4_dataT = q4_data.T\n",
    "q4a = np.nanmax(q4_dataT[(q4_date >= 201804) & (q4_date <= 202003)], axis = 0)\n",
    "for num in range(len(q4_name)):\n",
    "    print(f\"The maximum return for {q4_name[num]} is {q4a[num]:6.4f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc244ba6-a22f-49d1-af25-146840d9826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which of 4 stocks have lowest correlation in 2020\n",
    "np.corrcoef(q4_data[:,(q4_date>=202001)&(q4_date<=202012)])\n",
    "q4b_tup = ('StockB','StockD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd5fe07-24c8-4f14-96d3-fd54509d8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#high book-to-market value ratio (value companies) and companies with a low book-to-market value ratio (growth)\n",
    "# positive hml means value, neg means growth\n",
    "\n",
    "# positive sml means small, negative means large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c654baca-b30b-481d-aa69-3200ceb162bd",
   "metadata": {},
   "source": [
    " Use a regression specification to test whether StockB's daily return in 2018 is statistically significantly different (at the 5-percent level) from its daily return in 2019 and 2020. Extract the relevant parameter and p-value from the output of reg_m() and use these values to print a statement that explains whether the estimated difference in CAPM betas is statistically significant from zero at the 5-percent level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b5736-5577-49c4-8730-56a69a93230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull data for B from 2018-2020\n",
    "b = rets[(date>='20180101')*(date<='20201231'),ticker=='StockB']\n",
    "#This the subset of data for 2018-2020\n",
    "date2 = date[(date>='20180101')*(date<='20201231')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a041a0c-bb71-4e92-94ea-d22e3617f425",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.where(date2>'20181231',1,0)\n",
    "# puts 1 if date is in 2019-2020\n",
    "# [1 0/1] 0/1 is for if date is later or not\n",
    "b  = b.reshape(len(x1),1)\n",
    "x1 = x1.reshape(len(x1),1)\n",
    "reg_out = reg_m(b,x1)\n",
    "reg_out.summary(xname=['Constant','Constant*(2019-2020)'])\n",
    "if reg_out.pvalues[1]<= 0.05:\n",
    "    print(f\"Yes, stock B's return in 2019-2020 is statistically significantly different in 2018.\\n\\\n",
    "     The difference of {reg_out.params[1]:7.4f} is statistically significant with p-value of {reg_out.pvalues[1]:6.4f}.\") \n",
    "else:\n",
    "    print(f\"No, stock B's return in 2019-2020 is statistically significantly different in 2018.\\n\\\n",
    "     The difference of {reg_out.params[1]:7.4f} is statistically insignificant with p-value of {reg_out.pvalues[1]:6.4f}.\") \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
