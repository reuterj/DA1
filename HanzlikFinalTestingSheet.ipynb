{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67332a72-3cbd-4aae-838e-51673ad259cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caroline Hanzlik Testing Sheet\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def reg_m(y, x):\n",
    "    X = np.hstack((np.ones((len(x),1)), x))     # adds column of ones to X\n",
    "    results = sm.OLS(y, X).fit()                # creates object containing regression results\n",
    "    return results\n",
    "\n",
    "def float_formatter(x):\n",
    "    return \"{:8.6f}\".format(x)\n",
    "np.set_printoptions(formatter={'float_kind':float_formatter})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bae8cc3-5273-4798-9c32-60217e837756",
   "metadata": {},
   "source": [
    "## 1. Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de12a14a-d422-4e1f-9e72-b0658c22513a",
   "metadata": {},
   "source": [
    "Use a simulation to determine the distribution of future values of a portfolio that invests in small-cap equity for the first 10 years, invests in large-cap equity for the next 10 years, and invests in short-term US government bonds for the final 10 years. \n",
    "- The initial investment amount is \\\\$100,000.\n",
    "- The expected returns and standard deviations for each asset type should be taken from the table near the topic of Topic 1.7.5 in the notebook for Topic 1.7 on Canvas.\n",
    "- Any net returns that are less than -100% should be replaced with -99% (which will prevent your portfolio value from hitting zero).\n",
    "- After you have created your simulation to create a list containing the future values in year 30 for each 30 year investment horizon, please create a simple text table  that includes the following statements: average future value, median future value, minimum future value, maximum future value, and the 25th and 75th percentiles. Finally, your table should also include the average of the natural logarithm of each future value (i.e., take the natural logarithm of each future value and then calculate the average of these natural logarithms).\n",
    "- The final version of your simulation should involve 10000 iterations. However, start with 1 until you get the basic FV calculation to work and then scale up to 100 until your summary statistics are working as intended. Finally, scale all the way up to 10000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a0eea-4425-41df-b87f-c3584b3ce867",
   "metadata": {},
   "source": [
    "consider the following average annual returns and standard deviations of annual returns for three types of investments, calculated by <i>Ibbotson Associates</i> using data from 1926-2013.\n",
    "<table border=\"0\">\n",
    "   <tr>\n",
    "    <th>Investment</th>\n",
    "    <th>Average Return</th>\n",
    "    <th>Std Dev of Return</th>\n",
    "   </tr>\n",
    "   <tr>\n",
    "    <td>Short-term US government bonds</td>\n",
    "    <td>3.5%</td>\n",
    "    <td>3.1%</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "    <td>Large-cap US stocks</td>\n",
    "    <td>10.1%</td>\n",
    "    <td>20.2%</td>\n",
    "   </tr>\n",
    "   <tr>\n",
    "    <td>Small-cap US stocks</td>\n",
    "    <td>12.5%</td>\n",
    "    <td>32.3%</td>\n",
    "   </tr>\n",
    "  </table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c6c7d-f158-43c5-b7fe-0587ab634e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = []\n",
    "invest_returns = [(.035, .031), (.101, .202), (.125, .323)] # (Return, Standard Deviation)\n",
    "\n",
    "\n",
    "for item in range(10000):\n",
    "    # This does 30 years:\n",
    "    ii = 100000\n",
    "    for investment in range (10):\n",
    "        ii = ii * (1+ max(random.normalvariate(invest_returns[0][0],invest_returns[0][1]),-0.99))      # bonds\n",
    "        ii = ii * (1+ max(random.normalvariate(invest_returns[1][0],invest_returns[1][1]),-0.99))  # large cap\n",
    "        ii = ii * (1+ max(random.normalvariate(invest_returns[2][0],invest_returns[2][1]),-0.99))  # small cap\n",
    "\n",
    "    values.append(ii)\n",
    "\n",
    "    \n",
    "q25 = sorted(values)[2500]\n",
    "q75 = sorted(values)[7500]\n",
    "\n",
    "# Statistics on the List of Values\n",
    "print(\"Average Future Value:      ${:15,.2f}\".format(statistics.mean(values)))\n",
    "print(\"Median FV:     ${:15,.2f}\".format(statistics.median(values)))\n",
    "print(\"Minimum FV:   ${:15,.2f}\".format(min(values)))\n",
    "print(\"Maximum FV:   ${:15,.2f}\".format(max(values)))\n",
    "print(\"25th Percentile: ${:15,.2f}\".format(q25))\n",
    "print(\"75th Percentile:   ${:15,.2f}\".format(q75))\n",
    "\n",
    "# any net returns  that are less than -100% should be replaced with -99% "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b69853-3cf6-4f6e-bf67-93c011994827",
   "metadata": {},
   "source": [
    "This is a variation of the question above. Use a simulation with 100,000 iterations to compare the average utility associated with the outcomes of two portfolios. In both cases, we are going to focus on the average utility based on portfolio values at the end of five years. Portfolio A invests 100% in large-cap equity. Portfolio B invests 30% in short-term government bonds and 70% in small-cap equity (and is not ever rebalanced). Assume that both portfolios are initially worth $100,000. Which portfolio generates the higher average utility, when utility is measured as the <b>square root</b> of the portfolio value after five years of returns? Use an if-else statement to print the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e384b2-5e4b-4be9-861b-67c1cf96df74",
   "metadata": {},
   "outputs": [],
   "source": [
    "invest_returns = [(.035, .031), (.101, .202), (.125, .323)] # (Return, Standard Deviation)\n",
    "\n",
    "port_a = []\n",
    "port_b = []\n",
    "\n",
    "for item in range(10000):\n",
    "    for investment in range (30):\n",
    "        ii = 100000\n",
    "        ii = ii * (1+ max(random.normalvariate(invest_returns[1][0],invest_returns[1][1]),-0.99))  # large cap\n",
    "\n",
    "    port_a.append(ii**(1/2))\n",
    "    #port_a\n",
    "\n",
    "    for investment in range (30):\n",
    "        ii_bonds = 0.3*100000\n",
    "        ii_small_cap = 0.7*100000\n",
    "        ii_bonds = ii_bonds * (1+ max(random.normalvariate(invest_returns[0][0],invest_returns[0][1]),-0.99))      # bonds\n",
    "        ii_small_cap = ii_small_cap * (1+ max(random.normalvariate(invest_returns[2][0],invest_returns[2][1]),-0.99))  # small cap\n",
    "\n",
    "        total = ii_bonds + ii_small_cap\n",
    "\n",
    "    port_b.append(total**(1/2))\n",
    "    #port_b\n",
    "    \n",
    "a_mean = statistics.mean(port_a)\n",
    "b_mean = statistics.mean(port_b)\n",
    "print(f\"Portfolio A Average Utility: {a_mean}\")\n",
    "print(f\"Portfolio B Average Utility: {b_mean}\")\n",
    "\n",
    "if a_mean > b_mean:\n",
    "    print(\"Portfolio A has the highest average utility!\")\n",
    "else:\n",
    "    print(\"Portfolio B has the highest average utility!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151c8ca1-5bbf-4aca-90f3-03a817cdd043",
   "metadata": {},
   "source": [
    "- $ret_d = \\left(\\frac{p_1}{p_0}\\right) ^ \\frac{1}{n} - 1$\n",
    "\n",
    "- $annualized = (1 + ret_d)^{365} - 1$\n",
    "\n",
    "- $SR_i = \\frac{Return_i - r_{rf}}{Standard Deviation_i}$\n",
    "\n",
    "- $beta= \\frac{corrcoef(x,y) * std(y)}{Standard Deviation_x}$\n",
    "\n",
    "- $arithmetic avg.= sum(values)/len(values)$\n",
    "\n",
    "The correlation between variables X and Y is defined as:\n",
    "\n",
    "- $$\\rho_{X,Y} = \\frac{Cov(X,Y)}{\\sqrt{Var(X)} \\sqrt{Var(Y}}$$\n",
    "\n",
    "If we know the correlation coefficient and the variances, we can calculate:\n",
    "\n",
    "- $$Cov(X,Y) = \\rho_{X,Y} \\cdot \\sqrt{Var(X)} \\cdot \\sqrt{Var(Y)}$$\n",
    "\n",
    "When working with variables $X$ and $Y$, the covariance matrix is:\n",
    "\n",
    "- $$\n",
    "\\left[\n",
    "    \\begin{array}{cc} \n",
    "        Var(X) & Cov(X,Y) \\\\ \n",
    "        Cov(X,Y) & Var(Y) \\\\ \n",
    "    \\end{array} \n",
    "\\right]\n",
    "$$\n",
    "\n",
    "\n",
    "This is what the function <b>np.cov</b> calculates using the sample statistics.\n",
    "- <b>np.mean()</b> returns mean (overall or along axis)\n",
    "\n",
    "Covariance measures the joint variability of two random variables. Covariance can be positive, negative, or zero, indicating the nature and direction of the relationship between the variables.\n",
    "- A positive covariance indicates that as one variable increases, the other variable tends to increase.\n",
    "- A negative covariance indicates that as one variable increases, the other variable tends to decrease.\n",
    "- A covariance near zero suggests a weak or no linear relationship between the variables.\n",
    "\n",
    "Using CAPM to Simulate Correlated Returns. Recall that the CAPM says:\n",
    "\n",
    "- $E[r] = r_{rf} + \\beta (r_m - r_{rf})$\n",
    "\n",
    "Stocks with higher values of beta will have returns that are more highly correlated with each other, everything else equal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1aacf4-72fa-4bc6-b079-455fd155d08c",
   "metadata": {},
   "source": [
    "## 2. Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cce0a1-8f2c-4bf5-8b9d-8e7e0047f94e",
   "metadata": {},
   "source": [
    "Character Codes\n",
    "- .  = dot matches to any character except line break\n",
    "- \\w = word character (letters and digits but not space)\n",
    "- \\d = digit\n",
    "- \\D = anything but a digit\n",
    "- \\S = non-whitespace\n",
    "- \\s = whitespace\n",
    "- \\b = word boundary (must be used inside r'')\n",
    "- \\\\. = actual dot\n",
    "\n",
    "Quantifiers\n",
    "- \\+ = 1 or more\n",
    "- {3} = exactly three\n",
    "- {2,4} = between two and four\n",
    "- {3,} = three or more\n",
    "- \\* = 0 or more\n",
    "- ? = once or none\n",
    "- ^ = not (and also be used to indicated beginning of the string)\n",
    "- $ = used to indicated end of the string\n",
    "- | = or\n",
    "\n",
    "r' ' = raw function; Python does not process \\ and similar characters before processing regular expression\n",
    "\n",
    "- [0-9] will match any digit (ASCII values 48 through 57)\n",
    "- [A-Z] will match any uppercase letter in A-Z (ASCII values 65 through 90)\n",
    "- [A-Za-z] will match any uppercase letter in A-Z (ASCII values 65 through 90) and any lowercase letter in a-z (97-122)\n",
    "- [A-z] will match ASCI values 65-122 which includes \\[ \\ \\] ^ _ ` (ASCII values 91-96)\n",
    "\n",
    "We can use the <b>.join()</b> command to convert a list into a string and then use <b>re.findall()</b> to extract all matches within the (possible quite long) string.\n",
    "\n",
    "When we use \\( \\) within our expression to search for subpatterns, Python returns a tuple containing the matches.\n",
    "\n",
    "words = sorted(list(set(words)))    # uses set() to eliminate duplicates, then converts set to list, then sorts list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b47757-0097-4f3e-ba3c-d7a0ba51fd5d",
   "metadata": {},
   "source": [
    "## 3. Function Processing Lists (lol)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11b05ff-e1b2-40d9-860e-a256512804e2",
   "metadata": {},
   "source": [
    "- Define a function(x) that takes one or more arguments\n",
    "    - may need to instatiate lists, counters within the function\n",
    "    - will involve some sort of if statement logic, e.g. if i==j, where I and J represent matching keywords, then count += 1 ... or something similar\n",
    "- Note: when processing generated list data into an output array\n",
    "    - Take the list you are generating (and .append values into it) then use np.array(list) \n",
    "    - When appending list items, be sure to use .append() and then brackets within it .append([]), or else the function will not run\n",
    "    - return the array within the function itself and call it using function(data) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7744af4e-3d88-45ec-bcd2-240c36a5124b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('it', 47)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume we have a string that we need to count the words of, the final answer returning the most common word in the list.\n",
    "text = 'work it make it do it makes us harder better faster stronger more than hour hour never ever after work is over work it make it do it makes us harder better faster stronger work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over work it harder do it faster more than ever hour work is never over work it harder make it better do it faster makes us stronger more than ever hour after hour work is never over'\n",
    "\n",
    "# 'test' converts the string into a list of words\n",
    "test = text.split(' ')\n",
    "#print(test)\n",
    "\n",
    "# Now we need to create a function which determines which word is the most common...\n",
    "def popular(l):\n",
    "    words = []\n",
    "    for i in list(set(l)):\n",
    "        count = 0\n",
    "        for j in test: \n",
    "            if i==j:\n",
    "                count += 1\n",
    "        words.append((count, i))\n",
    "    return sorted(words)[-1][-1], sorted(words)[-1][0]\n",
    "popular(test)\n",
    "\n",
    "# The return line is saying the following\n",
    "# sorted(words)[-1] - Return the count of the most common word in the list, and the word itself\n",
    "# sorted(words)[-1][0] - returns just the count\n",
    "# sorted(words)[-1][-1], sorted(words)[-1][0] - returns the word, count ('word', #)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409a3055-c45c-4db8-a1e2-0124d117cf87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('these', 'are', ['some', 'words', 'in', 'a', 'list'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use this when data is in format ['a','b','c','d']\n",
    "\n",
    "some_letters = ['these,are,some,words,in,a,list']\n",
    "\n",
    "for string in some_letters: \n",
    "    first, second, *rest = string.split(',')\n",
    "\n",
    "first, second, rest\n",
    "\n",
    "# notice how instantiating rest with '*rest' takes the remaining characters and creates a mini list of them "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d389ff49-49e6-4c11-9675-19178018ca29",
   "metadata": {},
   "source": [
    "Certainly! Here's a cheat sheet on functions for processing lists in Python:\n",
    "\n",
    "### Basic List Operations:\n",
    "\n",
    "1. **Accessing Elements:**\n",
    "   ```python\n",
    "   element = my_list[index]  # Access element at index\n",
    "   ```\n",
    "\n",
    "2. **Slicing:**\n",
    "   ```python\n",
    "   sub_list = my_list[start_index:end_index] (end index not exclusive)\n",
    "   ```\n",
    "\n",
    "3. **Appending and Extending:**\n",
    "   ```python\n",
    "   my_list.append(new_element)  # Add element to end\n",
    "   my_list.extend(another_list)  # Add elements from another list\n",
    "   ```\n",
    "\n",
    "4. **Inserting and Removing:**\n",
    "   ```python\n",
    "   my_list.insert(index, element)  # Insert element at index\n",
    "   my_list.remove(element)         # Remove first occurrence of element\n",
    "   ```\n",
    "\n",
    "### Common Functions:\n",
    "- length = len(my_list)  # Get length of the list\n",
    "- maximum = max(my_list)\n",
    "- minimum = min(my_list)\n",
    "- total = sum(my_list)\n",
    "- index = my_list.index(element)  # Get the index of an element\n",
    "- occurrences = my_list.count(element)  # Count occurrences of an element\n",
    "\n",
    "### Sorting:\n",
    "   my_list.sort()  # In-place sorting\n",
    "   sorted_list = sorted(my_list)  # Returns a new sorted list\n",
    "\n",
    "### Filtering with filter():\n",
    "filtered_list = list(filter(lambda x: x > 0, my_list))\n",
    "\n",
    "\n",
    "### List Iteration:\n",
    "\n",
    "1. **For Loop:**\n",
    "   ```python\n",
    "   for item in my_list:\n",
    "       # Process each item\n",
    "   ```\n",
    "\n",
    "2. **enumerate():**\n",
    "   ```python\n",
    "   for index, item in enumerate(my_list):\n",
    "       # Process each item with its index\n",
    "   ```\n",
    "\n",
    "3. **zip():**\n",
    "   ```python\n",
    "   for item1, item2 in zip(list1, list2):\n",
    "       # Process corresponding elements from both lists\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d695cc0-b6ce-47dc-96bc-550778388f53",
   "metadata": {},
   "source": [
    "## 4. Processing Arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31763e91-e8ff-470f-a1b6-6381172290c6",
   "metadata": {},
   "source": [
    "#### Summing Elements Within Arrays\n",
    "\n",
    "- axis = None performs function on <b>all</b> elements of array\n",
    "- axis = 0 performs function separately for each <b>column</b> of array\n",
    "- axis = 1 performs function separately for each <b>row</b> of array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c2b91f-e7f1-4e12-8b1c-e03e99580e85",
   "metadata": {},
   "source": [
    "- <b>np.median()</b> returns median (overall or along axis)\n",
    "- <b>np.min()</b> returns minimum (overall or along axis)\n",
    "- <b>np.max()</b> returns maximum (overall or along axis)\n",
    "- <b>np.percentile()</b> returns percentile (integer between 0 and 100) (overall or along axis)\n",
    "- <b>np.ptp()</b> returns difference between maximum and minimum (overall or along axis)\n",
    "- <b>np.std()</b> returns standard deviation  (overall or along axis)\n",
    "- <b>np.var()</b> returns standard deviation  (overall or along axis)\n",
    "- <b>np.sqrt()</b> calculates the square root of each element\n",
    "- <b>np.log()</b> calculates the natural logarithm of each element\n",
    "- <b>np.sign()</b> calculates the sign of each element: 1 (positive), 0 (zero), or -1 (negative)\n",
    "- <b>np.exp()</b> calculates the exponent $e^x$ of each element\n",
    "\n",
    "We might want to keep track of the sum as we add each element to all previous elements, which is useful when simulating random walks. If so, we can use <b>.cumsum()</b>.\n",
    "\n",
    "Or, we might want to keep track of the product as we multiply each element by all previous elements, which is useful when simulating portfolio values. In this case, we can use <b>.cumprod()</b>.\n",
    "\n",
    "- <b>np.random.random()</b> returns array containing random values from uniform [0,1)\n",
    "- <b>np.cov(x,y)</b> estimates covariance matrix\n",
    "- <b>np.corrcoef(x,y)</b> estimates matrix of correlation coefficients\n",
    "- <b>np.where()</b> allows us to replace some values in an array with other values\n",
    "\n",
    "### Transposing Array\n",
    "<b>.T</b> converts row 0 into column 0, row 1 into column 1, row 2 into column 2, etc.\n",
    "\n",
    "### Combining + Spliting Arrays\n",
    "<b>np.random.normal($\\mu$, $\\sigma$, (x,y))</b> generates array of random variables from normal distribution, with mean $\\mu$ and standard deviation $\\sigma$\n",
    "<b>np.concatenate((),axis=#)</b> combines the arrays within the inner (); axis determines whether new array added to bottom of existing array (new rows) or on the side of existing array (new columns)\n",
    "\n",
    "- <b>np.vstack(())</b> can also be used to stack arrays vertically. Notice the double \\( \\).\n",
    "- <b>np.hstack(())</b> can also be used to stack arrays horizontally. Notice the double \\( \\).\n",
    "- <b>np.split(array, [$x, y$])</b> will break an array into three smaller arrays. The second array begins with row $x$ and the third array begins with row $y$ (where rows are numbered from 0 to number of rows-1). You can also use <b>vsplit()</b> and <b>hsplit()</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb48f7a1-6979-43ff-baef-7340cba8ab8a",
   "metadata": {},
   "source": [
    "### np.cumprod()\n",
    "returns = np.array([0.05, 0.03, -0.02, 0.01])\n",
    "\n",
    "- <b>Gross_value</b> = np.cumprod(1 + returns) \n",
    "\n",
    "- <b>Net_return</b> = np.cumprod(1 + returns) - 1                \n",
    "\n",
    "- <b>Future_value</b> = np.cumprod(1 + returns) * initial_investment\n",
    "\n",
    "net return = gross return - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c30815c-654e-4524-b2db-130e5b0fe92c",
   "metadata": {},
   "source": [
    "## 5. Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe44896-ef2e-4c03-baf1-b5bb2f72d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "ff_name = np.loadtxt('ff_name.txt')  # Replace 'ff_name.txt' with the actual filename\n",
    "ff_date = np.loadtxt('ff_date.txt')\n",
    "ff_ret = np.loadtxt('ff_ret.txt')\n",
    "stock_name = np.loadtxt('stock_name.txt')\n",
    "stock_date = np.loadtxt('stock_date.txt')\n",
    "stock_ret = np.loadtxt('stock_ret.txt')\n",
    "\n",
    "# Merge datasets if needed (use pandas or numpy)\n",
    "# Example using numpy:\n",
    "# ff_data = np.column_stack((ff_date, ff_ret))\n",
    "# stock_data = np.column_stack((stock_date, stock_ret))\n",
    "# merged_data = np.concatenate((ff_data, stock_data), axis=1)\n",
    "\n",
    "# Fama-French 3-factor model\n",
    "# Assuming 'ff_ret' and 'stock_ret' are the returns columns\n",
    "y = stock_ret\n",
    "x_ff = np.column_stack((np.ones_like(ff_ret), ff_ret, ff_name))  # Adjust for your factors\n",
    "x_stock = np.column_stack((np.ones_like(stock_ret), stock_ret, stock_name))  # Adjust for your factors\n",
    "\n",
    "results_ff = reg_m(y, x_ff)\n",
    "results_stock = reg_m(y, x_stock)\n",
    "\n",
    "# Ordinary Least Squares (OLS) regression\n",
    "# Assuming 'ff_ret' and 'stock_ret' are the returns columns\n",
    "y_ols = stock_ret\n",
    "x_ols = np.column_stack((np.ones_like(stock_ret), ff_ret))  # Adjust for your factors\n",
    "\n",
    "results_ols = reg_m(y_ols, x_ols)\n",
    "\n",
    "# Print regression results\n",
    "print(\"Fama-French 3-factor model for FF Data:\")\n",
    "print(results_ff.summary())\n",
    "\n",
    "print(\"\\nFama-French 3-factor model for Stock Data:\")\n",
    "print(results_stock.summary())\n",
    "\n",
    "print(\"\\nOLS Regression Results:\")\n",
    "print(results_ols.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f06146c-04da-40da-acdc-fa2310d7f524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST A\n",
    "ff_name = np.load('q5a_ff_name.npy')\n",
    "ff_date = np.load('q5a_ff_date.npy')\n",
    "ff_ret = np.load('q5a_ff_ret.npy')\n",
    "\n",
    "stock_name = np.array(['A', 'B', 'C', 'D'])\n",
    "stock_date = np.load('q5a_stock_date.npy')\n",
    "stock_ret = np.load('q5a_stock_ret.npy')\n",
    "\n",
    "# Fama-French 3-factor model for Stock A\n",
    "a_rf = stock_ret[:, stock_name == 'A'] - ff_ret[:, ff_name == 'rf']\n",
    "results_ff_stock_a = reg_m(a_rf, ff_ret[:, 0:3])\n",
    "\n",
    "# Print regression results\n",
    "print(\"Fama-French 3-factor model for Stock A:\")\n",
    "print(results_ff_stock_a.summary(xname=['Alpha', 'Mktrf Beta', 'SMB Beta', 'HML Beta']))\n",
    "\n",
    "# Interpretation\n",
    "\"\"\"\n",
    "- **Alpha:** The intercept represents the abnormal return for Stock A not explained by market, SMB, and HML factors.\n",
    "- **Mktrf Beta:** The coefficient is the sensitivity of Stock A's returns to market movements.\n",
    "- **SMB Beta:** Indicates the sensitivity of Stock A to the size factor.\n",
    "- **HML Beta:** Indicates the sensitivity of Stock A to the value factor.\n",
    "\"\"\"\n",
    "\n",
    "# Average return calculation for stocks in 2019 and 2020\n",
    "average_returns_2019_2020 = np.mean(stock_ret[(stock_date >= \"20190101\") * (stock_date <= \"20201231\")], axis=0)\n",
    "\n",
    "# OLS regression to test returns difference for stocks B and C in 2020 vs. stocks A and D\n",
    "a = stock_ret[(stock_date >= \"20200101\") * (stock_date <= \"20201231\"), :][:, stock_name == 'A']\n",
    "b = stock_ret[(stock_date >= \"20200101\") * (stock_date <= \"20201231\"), :][:, stock_name == 'B']\n",
    "c = stock_ret[(stock_date >= \"20200101\") * (stock_date <= \"20201231\"), :][:, stock_name == 'C']\n",
    "d = stock_ret[(stock_date >= \"20200101\") * (stock_date <= \"20201231\"), :][:, stock_name == 'D']\n",
    "\n",
    "# Check if shapes match\n",
    "print(a.shape == b.shape == c.shape == d.shape)\n",
    "\n",
    "# Stack returns and design matrix\n",
    "r = np.vstack((a, b, c, d))\n",
    "x = np.vstack((np.ones((len(a), 1)), np.zeros((len(b), 1)), np.zeros((len(c), 1)), np.ones((len(d), 1))))\n",
    "\n",
    "# Perform OLS regression\n",
    "reg_out = reg_m(r, x)\n",
    "\n",
    "# Print regression results\n",
    "print(\"OLS Regression Results:\")\n",
    "print(reg_out.summary(xname=[\"(Ave B and C)\", \"(Ave A and D) - (Ave B and C)\"]))\n",
    "\n",
    "# Interpretation of OLS regression results\n",
    "if reg_out.pvalues[1] <= 0.05:\n",
    "    print(\"Yes, stocks A and D do have statistically significantly different returns.\")\n",
    "else:\n",
    "    print(\"No, stocks A and D do not have statistically significantly different returns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a3b995-0e53-42e0-b11c-807233b6ae2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST B\n",
    "ff_name = np.array(['mktrf', 'smb', 'hml', 'rf'])\n",
    "ff_ret = np.load('q5b_ff_ret.npy')\n",
    "ff_date = np.load('q5b_ff_date.npy')\n",
    "\n",
    "ticker = np.array(['A', 'B'])\n",
    "rets = np.load('q5b_stock_ret.npy')\n",
    "date = np.load('q5b_stock_date.npy')\n",
    "\n",
    "# Estimate the CAPM model for stock A\n",
    "a_rf = (rets[:, 0] - ff_ret[:, 3]).reshape(1258, 1)\n",
    "ff_1 = ff_ret[:, ff_name == 'mktrf'].reshape(1258, 1)\n",
    "reg_out_capm = reg_m(a_rf, ff_1)\n",
    "\n",
    "# Print CAPM regression results\n",
    "print(\"CAPM Model for Stock A:\")\n",
    "print(reg_out_capm.summary(xname=['Alpha', 'Mktrf']))\n",
    "\n",
    "# Estimate the Fama-French 3-factor model for stock A\n",
    "ff_3 = ff_ret[:, ff_name != 'rf'].reshape(1258, 3)\n",
    "reg_out_ff = reg_m(a_rf, ff_3)\n",
    "\n",
    "# Print Fama-French 3-factor model regression results\n",
    "print(\"\\nFama-French 3-factor model for Stock A:\")\n",
    "print(reg_out_ff.summary(xname=['Alpha', 'Mktrf', 'SMB', 'HML']))\n",
    "\n",
    "# Interpretation of coefficients in the 3-factor model\n",
    "\"\"\"\n",
    "Alpha: Alpha is positive 0.0052 and highly statistically significant; p-value is 0.000.\n",
    "Mktrf: Market Beta is statistically indistinguishable from zero (p-value 0.374).\n",
    "SMB: SMB loading is well above one, with a p-value of 0.000. This is a small stock.\n",
    "HML: HML loading is well above one, with a p-value of 0.000. This is a value stock.\n",
    "\"\"\"\n",
    "\n",
    "# Use a regression specification to test whether the CAPM beta for stock B is statistically significantly different\n",
    "b_rf = (rets[:, 1] - ff_ret[:, 3]).reshape(1258, 1)\n",
    "mktrf = ff_ret[:, ff_name == 'mktrf'].reshape(1258, 1)\n",
    "later = np.where(date >= '20200101', 1, 0).reshape(1258, 1)\n",
    "l_mktrf = later * mktrf.reshape(1258, 1)\n",
    "X = np.hstack((mktrf, later, l_mktrf))\n",
    "reg_out_diff_beta = reg_m(b_rf, X)\n",
    "\n",
    "# Print regression results for the difference in CAPM betas\n",
    "print(\"\\nRegression Results for Difference in CAPM Betas:\")\n",
    "print(reg_out_diff_beta.summary(xname=['(Alpha 17-19)', '(Beta 17-19)', '(Alpha 20-21) - (Alpha 17-19)', '(Beta 20-21) - (Beta 17-19)']))\n",
    "\n",
    "# Interpretation of the difference in CAPM betas\n",
    "if reg_out_diff_beta.pvalues[3] <= 0.1:\n",
    "    print(f\"\\nYes, stock B's CAPM beta is statistically significantly different in the last two years. The\\n\"\n",
    "          f\"difference of {reg_out_diff_beta.params[3]:7.4f} is statistically significant (p-value of {reg_out_diff_beta.pvalues[3]:6.4f}).\")\n",
    "else:\n",
    "    print(f\"\\nNo, stock B's CAPM beta is not statistically significantly different in the last two years. The\\n\"\n",
    "          f\"difference of {reg_out_diff_beta.params[3]:7.4f} is not statistically significant (p-value of {reg_out_diff_beta.pvalues[3]:6.4f}).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d5bc29-e91a-455e-a4c4-18e0e3dd59b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST C\n",
    "ff_name = np.array(['mktrf', 'smb', 'hml', 'rf'])\n",
    "ff_ret = np.load('q5c_ff_ret.npy')\n",
    "ff_date = np.load('q5c_ff_date.npy')\n",
    "\n",
    "ticker = np.array(['StockA', 'StockB'])\n",
    "rets = np.load('q5c_stock_ret.npy')\n",
    "date = np.load('q5c_stock_date.npy')\n",
    "\n",
    "# Question 5a: Fama-French three-factor models for stock A\n",
    "a_rf = (rets[:, 0] - ff_ret[:, 3]).reshape(len(ff_ret), 1)\n",
    "ff_3 = ff_ret[:, ff_name != 'rf'].reshape(len(ff_ret), 3)\n",
    "reg_out_a = reg_m(a_rf, ff_3)\n",
    "\n",
    "# Print regression summary\n",
    "print(\"Fama-French 3-factor model for Stock A:\")\n",
    "print(reg_out_a.summary(xname=['Alpha', 'Mktrf', 'SMB', 'HML']))\n",
    "\n",
    "# Question 5b: Interpreting coefficients in the 3-factor model regression\n",
    "# Markdown interpretation\n",
    "\"\"\"\n",
    "Alpha: Alpha is positive 0.0036 and highly statistically significant; p-value is 0.000.\n",
    "Mktrf: Market Beta is statistically different from zero but well below one, implying below-average sensitivity to the market; 95% CI is 0.37 to 0.55.\n",
    "SMB: SMB loading is around -1, with p-value of 0.000. This is likely a large stock.\n",
    "HML: HML loading is around 2, with p-value of 0.000. This is likely a value stock.\n",
    "\"\"\"\n",
    "\n",
    "# Question 5c: Test whether StockB's daily return in 2018 is statistically significantly different from its daily return in 2019 and 2020\n",
    "b = rets[(date >= '20180101') * (date <= '20201231'), ticker == 'StockB']\n",
    "date2 = date[(date >= '20180101') * (date <= '20201231')]\n",
    "\n",
    "x1 = np.where(date2 > '20181231', 1, 0)\n",
    "b = b.reshape(len(x1), 1)\n",
    "x1 = x1.reshape(len(x1), 1)\n",
    "\n",
    "reg_out_b = reg_m(b, x1)\n",
    "\n",
    "# Print regression summary\n",
    "print(\"\\nRegression Results for Stock B's Returns:\")\n",
    "print(reg_out_b.summary(xname=['(Ave 2018)', '(Ave 2019-2020) - (Ave 2018)']))\n",
    "\n",
    "# Test whether the difference is statistically significant\n",
    "if reg_out_b.pvalues[1] <= 0.05:\n",
    "    print(f\"Yes, stock B's return in 2019-2020 is statistically significantly different than in 2018.\\n\"\n",
    "          f\"The difference of {reg_out_b.params[1]:7.4f} is statistically significant with p-value of {reg_out_b.pvalues[1]:6.4f}.\")\n",
    "else:\n",
    "    print(f\"No, stock B's return in 2019-2020 is statistically significantly different than in 2018.\\n\"\n",
    "          f\"The difference of {reg_out_b.params[1]:7.4f} is statistically insignificant with p-value of {reg_out_b.pvalues[1]:6.4f}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e9cbcb-9cdb-4f4d-96b2-ad28adc9c515",
   "metadata": {},
   "source": [
    "<b>(5 points) Question 2.</b> The arrays below contain the daily excess return on Costco's common stock, the daily excess return on the market portfolio (MKTRF), and the daily returns on the SMB and HML factors. The sample covers July 1, 2015 through June 30, 2020.\n",
    "\n",
    "- <b>Question 2a (1 point).</b> Calculate and print the mean and standard deviation of `cost_rf`.\n",
    "- <b>Question 2b (1 point).</b> Calculate and print the (4,4) correlation matrix for the excess return on Costco and the factor returns in `ff`.\n",
    "- <b>Question 2c (1 point).</b> Regress `cost_rf` on `MKTRF` using all daily returns from 2016 and 2017. Extract and report the estimated coefficient on the constant term and the p-value. (Do not print out .summary).)\n",
    "- <b>Question 2d (1 point).</b> Regress `cost_rf` on `MKTRF`, `SMB`, `HML` using all daily returns from 2018 and 2019. Report the 90% confidence intervals for `MKTRF`, `SMB`, and `HML`. Note: Applying <b>.conf_int(0.10)</b> to the output of reg_m generates 90% confidence intervals.\n",
    "- <b>Question 2e (1 point).</b> Use a for loop to calculate and print the CAPM beta and corresponding p-value for Costco, separately using data for each calendar year. Please only print the first four decimal places of each statistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf9340-7bb1-44c5-a89f-8c0cfee78c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates   = np.load('HW11_cost_dates.npy')    # can be used to create date filter\n",
    "cost_rf = np.load('HW11_cost_rf.npy')\n",
    "ff      = np.load('HW11_mktrf_smb_hml.npy')\n",
    "ff_name = np.array(['MKTRF','SMB  ','HML  '])\n",
    "\n",
    "dates.shape, cost_rf.shape, ff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab46ee38-46ef-4d1b-bbc0-7323cb3396e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = np.array([element[0:4] for element in dates])\n",
    "\n",
    "filter1 = (year=='2016') + (year=='2017')\n",
    "filter2 = (year=='2018') + (year=='2019')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a199b574-15b4-4659-9b1a-60c6dfc0cebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_mktrf = ff[:,0].reshape(len(ff),1)\n",
    "ff_mktrf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f9c808-882d-40b6-9dd2-1222d732405c",
   "metadata": {},
   "source": [
    "### Question 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370fb583-643e-4915-b7bf-48c10a72f657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean and Standard Deviation of Daily Returns\n",
    "print(np.mean(cost_rf), np.std(cost_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17630cc4-6fe8-4285-88e4-7c7c8d5e938e",
   "metadata": {},
   "source": [
    "### Question 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce67172-911d-49d1-8df6-d51b3f6d95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rets = np.hstack((cost_rf,ff))\n",
    "rets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fea0a89-2995-4f78-91cd-f37cd6c4c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.corrcoef(rets.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5a01b2-88d7-4ebf-b9a9-a3c72a7f2bfb",
   "metadata": {},
   "source": [
    "### Question 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e989e-fe10-4979-b65e-7c833c12fd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAPM Regression\n",
    "reg_out = reg_m(cost_rf[filter1],ff_mktrf[filter1])\n",
    "reg_out.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b680b986-ade0-46ed-a3d1-1eb220d3cf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_out.params[0], reg_out.pvalues[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe37646f-36a0-4ab3-89a5-81b14cf0df99",
   "metadata": {},
   "source": [
    "### Question 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc1d2dc-db37-48ce-832a-6b2aaee518e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FF Regression\n",
    "reg_out = reg_m(cost_rf[filter2],ff[filter2])\n",
    "reg_out.summary(xname=['alpha','mktrf','smb','hml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eee3bd-4b73-4f46-b003-19248ce1a49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_out.conf_int(0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d6a233-701f-4117-8a30-64b116077920",
   "metadata": {},
   "outputs": [],
   "source": [
    "ci = reg_out.conf_int(0.10)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30427ebc-dc53-45de-ab9c-529e42ca3300",
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(len(ff_name)):\n",
    "    print(f'{ff_name[num]}: ({ci[num][0]:7.4f}, {ci[num][1]:7.4f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32af23f4-1215-419d-97fa-4d487824471b",
   "metadata": {},
   "source": [
    "### Question 2e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560d289-6e4c-48ea-9254-ca17cbdd9a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "year = np.array([int(d[0:4]) for d in dates])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed371bd1-718d-4639-98f9-89e75a10d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(set(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f968de1-aafc-4e8a-a31b-f46130d8ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "year.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f439ae90-3e23-4424-ba9e-de6e46ec902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('year      beta     p-val')\n",
    "for y in sorted(set(year)):\n",
    "    reg_out = reg_m(cost_rf[year==y],ff_mktrf[year==y])\n",
    "    print(f'{y}    {reg_out.params[1]:.4f}    {reg_out.pvalues[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac4af5d-3e1e-4263-aa58-910ea35ae767",
   "metadata": {},
   "source": [
    "## Interpreting Regressions\n",
    "- Statistical Significance\n",
    "    - p < .05 is a statistically significant result @ 95% confidence interval\n",
    "    - T-stat ... calculated difference represented in units of standard error. The greater the magnitude of T, the greater the evidence against the null hypothesis.\n",
    "    \n",
    "Remember HML is growth and value, SMB is small and large cap...\n",
    "\n",
    "- If HML is > 0 with significance\n",
    "    - this is likely a value stock\n",
    "- If HML is < 0 with significance\n",
    "    - this is likely a growth stock \n",
    "- If HML is either positive or negative but insignificant\n",
    "    - whether or not the stock is growth or value is unclear, because the p-value is not significant enough\n",
    "- If SMB is > 0 with significance\n",
    "    - this is likely a small stock\n",
    "- If SMB is < 0 with significance\n",
    "    - this is likely a large stock\n",
    "- If HML is either positive or negative but insignificant\n",
    "    - whether or not the stock is large or small cap is unclear, because the p-value is not significant enough\n",
    "    \n",
    "<b>Conceptually, asking whether a regression coefficient is statistically different from zero at a specific significance level is the same as asking how likely we are to estimate a regression coefficient that is far from zero when the true value is zero. Think back to 2.4, where we estimated that the probability of 64 or more heads in 100 coin flips was less than 1% if Pr(Heads) = 50%, but almost 25% if the Pr(Heads) = 60%.</b>\n",
    "\n",
    "- \"No. Observations\" tells us how many observations were included in our regression. Unlike some statistical packages, Statsmodels.api.OLS will return an error message if any of the $y$ or $x$ values are missing. Unlike some numpy functions, however, Statsmodels.api.OLS allows data to be sorted in columns or rows.\n",
    "- \"Df Model\" tells us how many explanatory variables are included in the regression, excluding the constant.\n",
    "- \"R-squared\" tells us what fraction of the total variation in the dependent variable, $y$, can be explained by variation in the explanatory variable(s). In a univariate regression, we can calculate R-squared by squaring the correlation coefficient between $x$ and $y$.\n",
    "- \"coef\" for \"const\" is the estimated intercept.\n",
    "- \"coef\" for \"x1\" is the estimated slope on the only independent variable.\n",
    "- \"std err\" measures the precision of our estimated intercept and slope.\n",
    "- \"t\" is the t-statistic, which is simply the \"coef\" divided by the corresponding \"std err\". The larger this value, the less likely that the \"coef\" could have arisen by chance, if the population parameter were zero.\n",
    "- \"P>|t|\" is the p-value associated with a two-sided hypothesis test that the population parameter is zero. For example, it tells us how likely we are to observe a slope coefficient that is greater than 1.8717 or less than -1.8717 when the population slope is zero.\n",
    "- \"[0.025  0.975]\" tells us the lower and upper bounds of the 95% confidence interval for each parameter. In this example, we multiply the standard error by 1.984467454426692 and subtract from \"coef\" to obtain the lower bound. Similarly, we multiply the standard error by 1.984467454426692 and add to \"coef\" to obtain the upper bound. (In both cases, 1.984467454426692 is the 0.025% critical value for a t-statistic with 98 degrees of freedom; I asked Python to calculate this value below.)\n",
    "- If we estimate 1 million regressions based on random samples generated by the same underlying statistical model, we expect the population parameter to fall inside the estimated 95%-confidence interval 95% percent of the time!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564f37e0-064b-40fd-af97-c0938a832e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Q) Use a regression specification to test whether StockB's daily return in \n",
    "# 2018 is statistically significantly different \n",
    "#  (at the 5-percent level) from its daily return in 2019 and 2020. \n",
    "# Extract the relevant parameter and p-value from the output of \n",
    "#  reg_m() and use these values to print a statement that explains whether the \n",
    "# estimated difference in returns\n",
    "#  is statistically significant from zero at the 5-percent level.\n",
    "\n",
    "#1) Pull the arrays of data we need for the regression \n",
    "\n",
    "b = rets[(date>='20180101')*(date<='20201231'),ticker=='StockB']\n",
    "date_2 = date[(date>='20180101')*(date<='20201231')]\n",
    "\n",
    "#2) Instantiate regression variable \n",
    "x1 = np.where(date_2>'20181231',1,0)\n",
    "\n",
    "#3) Reshape data so that the array sizes match \n",
    "b = b.reshape(len(x1),1)\n",
    "x1 = x1.reshape(len(x1),1) \n",
    "\n",
    "#4) Regress\n",
    "reg_out = reg_m(b, x1)\n",
    "reg_out.summary(xname=['Constant','Constant*(2019-2020)'])\n",
    "\n",
    "#5) Explain statistical sign.@ 5% level \n",
    "if reg_out.pvalues[1]<= 0.05:\n",
    "    print(f\"Yes, stock B's return in 2019-2020 is statistically significantly different in 2018.\\n\\\n",
    "     The difference of {reg_out.params[1]:7.4f} is statistically significant with p-value of {reg_out.pvalues[1]:6.4f}.\") \n",
    "else:\n",
    "    print(f\"No, stock B's return in 2019-2020 is statistically significantly different in 2018.\\n\\\n",
    "     The difference of {reg_out.params[1]:7.4f} is statistically insignificant with p-value of {reg_out.pvalues[1]:6.4f}.\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
